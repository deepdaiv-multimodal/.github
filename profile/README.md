# deep daiv. Multimodal
This Organization is for archiving project repositories of deep daiv. Multimodal Team   

## Team Member
Mentor: [Yoorhim Cho](https://github.com/ofzlo)   
### ü¶ã 24' Spring
Member: [Jiwon Kim](https://github.com/hanajibsa), [Taekyung Kim](https://github.com/taekyungss), [Eunju Park](https://github.com/pej0918), [Hankyeol Lee](https://github.com/guts4)   
- KB-VQA Using Multimodal Larage Language Model(MLLM) [[code](https://github.com/deepdaiv-multimodal/24s-VQA-MLLM.git)]

### ‚òÉÔ∏è 24' Winter   
Member: [Jiwon Kim](https://github.com/hanajibsa), [Taekyung Kim](https://github.com/taekyungss), [Eunju Park](https://github.com/pej0918), [Hankyeol Lee](https://github.com/guts4)   
- Architecture Build Research for Learning Tri Modalities [[code](https://github.com/deepdaiv-multimodal/24w-Tri-Modalities)]

### üçÇ 23' Fall   
Member: [Jibin Song](https://github.com/jibin86), [Youna Shin](https://github.com/youna3515), [Heejae Yang](https://github.com/neulbo0829), [Yeabin Lim](https://github.com/binnnnnny), [Yongseong Lim](https://github.com/YongCastle), [Jinu Hong]()   
- The Imagination Becomes a Reality: Novel Text Generation Based to Custom Image Synthesis [[code](https://github.com/deepdaiv-multimodal/23f-custom-img-to-text)]
- Research for enhancing TempoToken [[code](https://github.com/deepdaiv-multimodal/23f-enhance-TempoToken)]

